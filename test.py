import argparse
import os
import time, calendar
import numpy as np 
import tqdm
import torch
import cv2
import json
from torch.utils.data import DataLoader
from PIL import Image, ImageDraw
from skimage.transform import resize
from dataloaders.datasets import simple
from modeling.deeplab import *
from dataloaders.utils import get_pascal_labels
from utils.metrics import Evaluator
from logger import LoggerHelper

# ì „ì—­ ë³€ìˆ˜ ì¶”ê°€ (í…ŒìŠ¤íŠ¸ìš© í™•ì¸ ì—¬ë¶€)
checked_pred = False
class Tester(object):
    def __init__(self, args, base_dir):
        if not os.path.isfile(args.model):
            raise RuntimeError("No checkpoint found at '{}'".format(args.model))
        
        self.args = args
        self.color_map = get_pascal_labels()

        if base_dir and len(base_dir):
            self.test_set = simple.SimpleSegmentation(args, base_dir=base_dir, split='test')
        else:
            self.test_set = simple.SimpleSegmentation(args, split='test')
        simple.SimpleSegmentation.NUM_CLASSES = args.num_classes
        self.num_classes = simple.SimpleSegmentation.NUM_CLASSES

        kwargs = {'num_workers': args.workers, 'pin_memory': True}
        self.test_loader = DataLoader(self.test_set, shuffle=True, **kwargs)

        # Define model
        self.model = DeepLab(num_classes=self.num_classes,
                        backbone=args.backbone,
                        output_stride=args.out_stride,
                        sync_bn=False,
                        freeze_bn=False)
        
        # Using cuda
        if args.gpu_ids and torch.cuda.is_available():
            if len(args.gpu_ids) > 1:
                self.device = torch.device("cuda")
                self.model = torch.nn.DataParallel(self.model, device_ids=self.args.gpu_ids)
            else: 
                self.device = torch.device("cuda:{}".format(args.gpu_ids[0]))
        else:
            self.device = torch.device('cpu')

        checkpoint = torch.load(args.model, map_location=self.device)
        self.model.load_state_dict(checkpoint['state_dict'])
        self.evaluator = Evaluator(self.num_classes)
        self.fwIoUs = []
        self.mIoUs = []
        self.elapsed_list = []  

    def save_pr_json(self, pred, pr_json_path, imagename):
        """
        PR ë§ˆìŠ¤í¬ì—ì„œ ì™¸ê³½ì„ ì„ ì¶”ì¶œí•˜ê³  JSON íŒŒì¼ë¡œ ì €ìž¥
        """
        # predê°€ numpy ë°°ì—´ì¸ì§€ í™•ì¸ í›„ ë³€í™˜
        if not isinstance(pred, np.ndarray):
            pred = np.array(pred)

        pred_mask = pred.astype(np.uint8)  # ì´ ë¶€ë¶„ ìˆ˜ì •

        # ì™¸ê³½ì„  ê²€ì¶œ
        contours, _ = cv2.findContours(pred_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        json_data = {"swelling": {}, "defects": []}

        for contour in contours:
            points = contour.reshape(-1, 2).tolist()  # (x, y) ì¢Œí‘œ ë³€í™˜
            json_data["defects"].append({"name": "Predicted", "points": points})

        # JSON ì €ìž¥
        with open(pr_json_path, "w", encoding="utf-8") as f:
            json.dump(json_data, f, indent=4)

    def add_pr_outline(self, image, pred):
        """
        PR ë§ˆìŠ¤í¬ì—ì„œ ê° í´ëž˜ìŠ¤ì˜ ê°œë³„ ì¸ìŠ¤í„´ìŠ¤ë¥¼ êµ¬ë³„í•˜ì—¬ ì™¸ê³½ì„ ì„ ì›ë³¸ ì´ë¯¸ì§€ì— ê²¹ì³ì„œ ì €ìž¥
        """
        # PIL.Image ê°ì²´ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜
        if isinstance(image, Image.Image):
            image = np.array(image)

        # ë§Œì•½ 4ì±„ë„(RGBA)ì´ë©´ 3ì±„ë„(RGB)ë¡œ ë³€í™˜
        if image.shape[-1] == 4:
            image = image[:, :, :3]

        # PR ë§ˆìŠ¤í¬ê°€ numpy ë°°ì—´ì´ ì•„ë‹ ê²½ìš° ë³€í™˜
        if not isinstance(pred, np.ndarray):
            pred = np.array(pred)

        # PR ë§ˆìŠ¤í¬ë¥¼ uint8ë¡œ ë³€í™˜
        pred = pred.astype(np.uint8)

        # í…ŒìŠ¤íŠ¸ìš© í•œ ë²ˆë§Œ ì¶œë ¥
        global checked_pred
        if not checked_pred:
            print(f"Initial pred shape: {pred.shape}, dtype: {pred.dtype}")
            checked_pred = True

        # PR ë§ˆìŠ¤í¬ê°€ RGB(3ì±„ë„)ì¸ì§€ í™•ì¸í•˜ê³  ë³€í™˜ í•„ìš” ì‹œ ë³€í™˜
        if len(pred.shape) == 3 and pred.shape[-1] == 3:
            pred = cv2.cvtColor(pred, cv2.COLOR_RGB2GRAY)
            print("Converted pred to Grayscale (1 channel)")

        # ìƒ‰ìƒ ë§¤í•‘ (RGB í˜•ì‹)
        color_map = {
            1: (0, 255, 0),   # ë°°í„°ë¦¬ ì™¸ê³½ì„  - ì´ˆë¡ìƒ‰
            2: (255, 0, 0),   # ì†ìƒ - ë¹¨ê°„ìƒ‰
            3: (0, 0, 255)    # ì˜¤ì—¼ - íŒŒëž€ìƒ‰
        }

        # ê°œë³„ ì¸ìŠ¤í„´ìŠ¤ ê°œìˆ˜ ì €ìž¥
        instance_counts = {}

        # í´ëž˜ìŠ¤ë³„ ì™¸ê³½ì„  ê²€ì¶œ
        for class_id, color in color_map.items():
            # **ë‹¨ì¼ ì±„ë„ (Grayscale)ë¡œ ë³€í™˜í•˜ì—¬ ì˜¤ë¥˜ ë°©ì§€**
            mask = (pred == class_id).astype(np.uint8) * 255

            # ê°œë³„ ì¸ìŠ¤í„´ìŠ¤ë¥¼ êµ¬ë³„í•˜ê¸° ìœ„í•´ Connected Components ì‚¬ìš©
            num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)
            instance_counts[class_id] = num_labels - 1  # ë°°ê²½(0) ì œì™¸

            for i in range(1, num_labels):  # 0ì€ ë°°ê²½ì´ë¯€ë¡œ ì œì™¸
                instance_mask = (labels == i).astype(np.uint8) * 255
                contours, _ = cv2.findContours(instance_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(image, contours, -1, color, 3)  # ì›ë³¸ ì´ë¯¸ì§€ì— ì™¸ê³½ì„  í‘œì‹œ (ë‘ê»˜ 3px)

        # ê²°ê³¼ ì €ìž¥ ê²½ë¡œ ì„¤ì •
        save_path = "logs/result"
        outlined_image = Image.fromarray(image)
        outlined_image.save(f"{save_path}/ì™¸ê³½ì„ .png")

        # ì¸ìŠ¤í„´ìŠ¤ ê°œìˆ˜ë¥¼ JSON íŒŒì¼ë¡œ ì €ìž¥
        with open(f"{save_path}/instance_counts.json", "w", encoding="utf-8") as f:
            json.dump(instance_counts, f, indent=4)

        return outlined_image


    def save(self, array, id, type, resize=None):
        r = array.copy()
        g = array.copy()
        b = array.copy()

        for i in range(self.num_classes):
            r[array == i] = self.color_map[i][0]
            g[array == i] = self.color_map[i][1]
            b[array == i] = self.color_map[i][2]
    
        rgb = np.dstack((r, g, b))

        img = Image.fromarray(rgb.astype('uint8'))
        if resize and (img.size[0] != resize[0] or img.size[1] != resize[1]):
            img = img.resize(resize, Image.NEAREST)

        filename = str(id) + '_' + type + '.png'
        img.save(os.path.join(self.args.save_dir, filename))

        return filename

    def add_mask_outline(image, mask, color, thickness=5):
        """ì›ë³¸ ì´ë¯¸ì§€ì— ì™¸ê³½ì„ ë§Œ ê²¹ì³ì„œ í‘œì‹œ"""
        image = image.copy()
        draw = ImageDraw.Draw(image)

        h, w = mask.shape
        for y in range(1, h - 1):
            for x in range(1, w - 1):
                # í˜„ìž¬ í”½ì…€ì´ ë°°ê²½ì´ ì•„ë‹ˆê³ , ì£¼ë³€ì— ë‹¤ë¥¸ í´ëž˜ìŠ¤(ì¦‰, ê²½ê³„ì„ )ê°€ ìžˆìœ¼ë©´ ì„ ì„ ê·¸ë¦¼
                if mask[y, x] > 0:
                    if (mask[y, x] != mask[y-1, x] or mask[y, x] != mask[y+1, x] or
                        mask[y, x] != mask[y, x-1] or mask[y, x] != mask[y, x+1]):
                        draw.line([(x-thickness//2, y-thickness//2), (x+thickness//2, y+thickness//2)], fill=color, width=thickness)

        return image

    def test(self):
        self.model.eval()
        self.model.to(device=self.device)

        LoggerHelper.getLogger().info("********************************************************************************")
        LoggerHelper.getLogger().info(f"Evaluation Started. (timestamp: {calendar.timegm(time.gmtime())})")
        LoggerHelper.getLogger().info(str(self.args).replace("Namespace(", "Argument("))
        LoggerHelper.getLogger().info("********************************************************************************")

        total = len(self.test_loader)
        for i, sample in tqdm.tqdm(enumerate(self.test_loader), total=total):
            image, target, imagename, imagesize = sample['image'], sample['label'], sample['imagename'], sample['imagesize']
            target = target.numpy()
            if torch.cuda.is_available():
                image = image.cuda()

            started = time.time()
            pred = None
            with torch.no_grad():
                if self.args.crop == "slide":
                    crop_size = self.args.crop_size
                    _, height, width = target.shape
                    pred = np.zeros((height, width), "uint8")
                    for x in range(0 + self.args.offset_width, width - self.args.offset_width, crop_size):
                        for y in range(0 + self.args.offset_height, height - self.args.offset_height, crop_size):
                            box = (x, y,
                                    x + crop_size if x + crop_size <  width else  width,
                                    y + crop_size if y + crop_size < height else height)
                            # image_cropped = np.array(image.crop(box))
                            output = self.model(image[:, :, y : box[3], x : box[2]])
                            pred[y : box[3], x : box[2]] = np.argmax(output[0].detach().cpu().clone().numpy(), axis=0)
                else:
                    output = self.model(image)
                    pred = np.argmax(output[0].detach().cpu().clone().numpy(), axis=0)

            elapsed = time.time() - started
            self.evaluator.add_batch(target[0], pred)
            fwIoU = self.evaluator.Frequency_Weighted_Intersection_over_Union()
            mIoU = self.evaluator.Mean_Intersection_over_Union()

            LoggerHelper.getLogger().info(f"[{i+1}/{total}] \"{os.path.basename(imagename[0])}\" predicted. mIoU: {mIoU:.4f}, fwIoU: {fwIoU:.4f}, Elapsed: {elapsed:.4f}s")

            if self.args.save_dir and len(self.args.save_dir):
                if not os.path.exists(self.args.save_dir):
                    os.makedirs(self.args.save_dir)
                savename = os.path.splitext(os.path.basename(imagename[0]))[0]
                pr_filename = self.save(pred, savename, "pr", (int(imagesize[0]), int(imagesize[1])) if self.args.crop == "none" else None)
                gt_filename = self.save(target[0], savename, "gt", (int(imagesize[0]), int(imagesize[1])) if self.args.crop == "none" else None)
                np.savetxt(os.path.join(self.args.save_dir, f"{savename}_cm.txt"), self.evaluator.confusion_matrix)

            self.evaluator.reset()
            self.fwIoUs.append(fwIoU)
            self.mIoUs.append(mIoU)
            self.elapsed_list.append(elapsed)

            pr_json_path = os.path.join(self.args.save_dir, f"{os.path.splitext(os.path.basename(imagename[0]))[0]}_pr.json")
            self.save_pr_json(pred, pr_json_path, imagename[0])

            # ðŸ“Œ **PR ì™¸ê³½ì„ ì„ ì›ë³¸ ì´ë¯¸ì§€ì— ì¶”ê°€í•˜ì—¬ ì €ìž¥**
            pr_outline_image = self.add_pr_outline(Image.open(imagename[0]).convert("RGB"), pred)
            pr_outline_image.save(os.path.join(self.args.save_dir, f"{os.path.splitext(os.path.basename(imagename[0]))[0]}_PR_ì™¸ê³½ì„ _ì›ë³¸ì´ë¯¸ì§€.png"))


        LoggerHelper.getLogger().info("********************************************************************************")
        LoggerHelper.getLogger().info(f"Evaluation Summary (timestamp: {calendar.timegm(time.gmtime())})")
        LoggerHelper.getLogger().info(f"Number of Datasets: {total}")
        LoggerHelper.getLogger().info(f"Mean IoU: {np.mean(self.mIoUs):.4f}")
        LoggerHelper.getLogger().info(f"Frequency Weighted IoU: {np.mean(self.fwIoUs):.4f}")
        LoggerHelper.getLogger().info(f"Prediction Elapsed: {np.sum(self.elapsed_list):.4f}s")
        LoggerHelper.getLogger().info(f"Average FPS: {total/np.sum(self.elapsed_list):.4f}")
        LoggerHelper.getLogger().info("********************************************************************************")


def main():
    parser = argparse.ArgumentParser(description='DeepLab v3+ Evaluation')
    
    # Essential params
    parser.add_argument('--num-classes', type=int, 
                        default=4,
                        # default=3,
                        help='number of classes (default: 4)')
    parser.add_argument('--gpu-ids', type=str, default='0',
                        help='use which gpu to train, must be a \
                        comma-separated list of integers only (default=0)')
    parser.add_argument('--backbone', default='drn', 
                        help='backbone name (default: drn)')
    parser.add_argument('--out-stride', type=int, default=16,
                        help='output stride')
    parser.add_argument('--model', type=str, 
                        default='weights/aihub2023_battery_rgb_c4_b640.pt',
                        # default='weights/easternsky_c3_b650.pt',
                        help='model path to be loaded')
    parser.add_argument('--save_dir', type=str, default='logs/result',
                        help='directory to save prediction')
    parser.add_argument('--base_dir', type=str, 
                        default='testset/RGB/20231023',
                        # default='testset/easternsky/20231013',
                        help='directory to evaluate dataset')

    # Params to use DataLoader
    parser.add_argument('--workers', type=int, default=1,
                        metavar='N', help='dataloader threads')

    parser.add_argument('--crop-size', type=int, 
                        default=640,
                        # default=650,
                        help='crop image size')
    parser.add_argument('--crop', type=str, default='slide',
                        help='crop type: slide, random, none')
    parser.add_argument('--offset_width', type=int, default=0,
                        help='offset width for inference (if crop: slide)')
    parser.add_argument('--offset_height', type=int, default=0,
                        help='offset height for inference (if crop: slide)')

    args = parser.parse_args()
    args.gpu_ids = [int(s) for s in args.gpu_ids.split(',')]

    tester = Tester(args, base_dir=args.base_dir)
    tester.test()


if __name__ == "__main__":
    main()